---
---

@article{MairFuSjolund:2024,
	author = {S. Mair and A. Fu and J. Sjölund},
	title = {Efficient Radiation Treatment Planning Based on Voxel Importance}, 
	journal = {Physics in Medicine and Biology},
	abbr = {PMB},
	volume = {69},
	number = {16},
	pages = {165031},
	month = {August},
	year = {2024},
	doi = {10.1088/1361-6560/ad68bd},
	html = {https://iopscience.iop.org/article/10.1088/1361-6560/ad68bd},
	pdf = {medphys/efficient_rtp.pdf},
	abstract = {Objective. Radiation treatment planning (RTP) involves optimization over a large number of voxels, many of which carry limited information about the clinical problem. We propose an approach to reduce the large optimization problem by only using a representative subset of informative voxels. This way, we drastically improve planning efficiency while maintaining the plan quality. Approach. Within an initial probing step, we pre-solve an easier optimization problem involving a simplified objective from which we derive an importance score per voxel. This importance score is then turned into a sampling distribution, which allows us to subsample a small set of informative voxels using importance sampling. By solving a—now reduced—version of the original optimization problem using this subset, we effectively reduce the problem’s size and computational demands while accounting for regions where satisfactory dose deliveries are challenging. Main results. In contrast to other stochastic (sub-)sampling methods, our technique only requires a single probing and sampling step to define a reduced optimization problem. This problem can be efficiently solved using established solvers without the need of modifying or adapting them. Empirical experiments on open benchmark data highlight substantially reduced optimization times, up to 50 times faster than the original ones, for intensity-modulated radiation therapy, all while upholding plan quality comparable to traditional methods. Significance. Our novel approach has the potential to significantly accelerate RTP by addressing its inherent computational challenges. We reduce the treatment planning time by reducing the size of the optimization problem rather than modifying and improving the optimization method. Our efforts are thus complementary to many previous developments.}
}

@article{FuTaastiZarepisheh:2024,
	author = {A. Fu and V. T. Taasti and M. Zarepisheh},
	title = {Simultaneous Reduction of Number of Spots and Energy Layers in Intensity Modulated Proton Therapy for Rapid Spot Scanning Delivery},
	journal = {Medical Physics},
	abbr = {MedPhys},
	month = {April},
	year = {2024},
	doi = {10.1002/mp.17070},
	html = {https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.17070},
	pdf = {medphys/reweighted_l1.pdf},
	supp = {supp/reweighted_l1_supplement.pdf},
	abstract = {Reducing proton treatment time improves patient comfort and decreases the risk of error from intra-fractional motion, but must be balanced against clinical goals and treatment plan quality. In this paper, we improved the delivery efficiency of spot scanning proton therapy by simultaneously reducing the number of spots and energy layers using the reweighted l1 regularization method. We formulated the proton treatment planning problem as a convex optimization problem with a cost function consisting of a dosimetric plan quality term plus a weighted l1 regularization term. We iteratively solved this problem and adaptively updated the regularization weights to promote the sparsity of both the spots and energy layers. The proposed algorithm was tested on four head-and-neck cancer patients, and its performance, in terms of reducing the number of spots and energy layers, was compared with existing standard l1 and group l2 regularization methods. We also compared the effectiveness of the three methods (l1, group l2, and reweighted l1) at improving plan delivery efficiency without compromising dosimetric plan quality by constructing each of their Pareto surfaces charting the trade-off between plan delivery and plan quality. The reweighted l1 regularization method reduced the number of spots and energy layers by an average over all patients of 40% and 35%, respectively, with an insignificant cost to dosimetric plan quality. From the Pareto surfaces, it is clear that reweighted l1 provided a better trade-off between plan delivery efficiency and dosimetric plan quality than standard l1 or group l2 regularization, requiring the lowest cost to quality to achieve any given level of delivery efficiency. In conclusion, reweighted l1 regularization is a powerful method for simultaneously promoting the sparsity of spots and energy layers at a small cost to dosimetric plan quality. This sparsity reduces the time required for spot scanning and energy layer switching, thereby improving the delivery efficiency of proton plans.},
	selected = {true}
}

@article{GouwFuDeasy:2024,
	author = {Z. A. R. Gouw and J. Jeong and A. Rimner and N. Y. Lee and A. Jackson and A. Fu and J.-J. Sonke and J. O. Deasy},
	title = {"Primer Shot" Fractionation with an Early Treatment Break is Theoretically Superior to Consecutive Weekday Fractionation Schemes for Early-Stage Non-Small Cell Lung Cancer},
	journal = {Radiotherapy and Oncology},
	abbr = {GREEN},
	volume = {190},
	number = {1},
	pages = {110006},
	month = {January},
	year = {2024},
	doi = {10.1016/j.radonc.2023.110006},
	html = {https://www.thegreenjournal.com/article/S0167-8140(23)09313-1/fulltext},
	pdf = {radonc/primer_shot.pdf},
	supp = {supp/primer_shot_supplement.zip},
	abstract = {Radiotherapy is traditionally given in equally spaced weekday fractions. We hypothesize that heterogeneous interfraction intervals can increase radiosensitivity via reoxygenation. Through modeling, we investigate whether this minimizes local failures and toxicity for early-stage non-small cell lung cancer (NSCLC). Previously, a tumor dose-response model based on resource competition and cell-cycle-dependent radiosensitivity accurately predicted local failure rates for early-stage NSCLC cohorts. Here, the model mathematically determined non-uniform inter-fraction intervals minimizing local failures at similar normal tissue toxicity risk, i.e., iso-BED3 (iso-NTCP) for fractionation schemes 18Gyx3, 12Gyx4, 10Gyx5, 7.5Gyx8, 5Gyx12, 4Gyx15. Next, we used these optimized schedules to reduce toxicity risk (BED3) while maintaining stable local failures (TCP). Optimal schedules consistently favored a “primer shot” fraction followed by a 2-week break, allowing tumor reoxygenation. Increasing or decreasing the assumed baseline hypoxia extended or shortened this optimal break by up to one week. Fraction sizes of 7.5 Gy and up required a single primer shot, while smaller fractions needed one or two extra fractions for full reoxygenation. The optimized schedules, versus consecutive weekday fractionation, predicted absolute LF reductions of 4.6%-7.4%, except for the already optimal LF rate seen for 18Gyx3. Primer shot schedules could also reduce BED3 at iso-TCP with the biggest improvements for the shortest schedules (94.6Gy reduction for 18Gyx3). A validated simulation model clearly supports non-standard “primer shot” fractionation, reducing the impact of hypoxia-induced radioresistance. A limitation of this study is that primer-shot fractionation is outside prior clinical experience and therefore will require clinical studies for definitive testing.}
}

@article{FuTaastiZarepisheh:2023,
	author = {A. Fu and V. T. Taasti and M. Zarepisheh},
	title = {Distributed and Scalable Optimization for Robust Proton Treatment Planning},
	journal = {Medical Physics},
	abbr = {MedPhys},
	volume = {50},
	number = {1},
	pages = {633--642},
	month = {January},
	year = {2023},
	doi = {10.1002/mp.15897},
	html = {https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.15897},
	pdf = {medphys/robust_proton.pdf},
	abstract = {The importance of robust proton treatment planning to mitigate the impact of uncertainty is well understood. However, its computational cost grows with the number of uncertainty scenarios, prolonging the treatment planning process. We developed a fast and scalable distributed optimization platform that parallelizes the robust proton treatment plan computation over the uncertainty scenarios. We modeled the robust proton treatment planning problem as a weighted least-squares problem. To solve it, we employed an optimization technique called the alternating direction method of multipliers with Barzilai–Borwein step size (ADMM-BB). We reformulated the problem in such a way as to split the main problem into smaller subproblems, one for each proton therapy uncertainty scenario. The subproblems can be solved in parallel, allowing the computational load to be distributed across multiple processors (e.g., CPU threads/cores). We evaluated ADMM-BB on four head-and-neck proton therapy patients, each with 13 scenarios accounting for 3 mm setup and 3.5% range uncertainties. We then compared the performance of ADMM-BB with projected gradient descent (PGD) applied to the same problem. For each patient, ADMM-BB generated a robust proton treatment plan that satisfied all clinical criteria with comparable or better dosimetric quality than the plan generated by PGD. However, ADMM-BB’s total runtime averaged about 6 to 7 times faster. This speedup increased with the number of scenarios. ADMM-BB is a powerful distributed optimization method that leverages parallel processing platforms, such as multicore CPUs, GPUs, and cloud servers, to accelerate the computationally intensive work of robust proton treatment planning. This results in (1) a shorter treatment planning process and (2) the ability to consider more uncertainty scenarios, which improves plan quality.}
}

@article{FuXingBoyd:2022,
	author = {A. Fu and L. Xing and S. Boyd},
	title = {Operator Splitting for Adaptive Radiation Therapy with Nonlinear Health Constraints},
	journal = {Optimization Methods and Software},
	abbr = {OMS},
	volume = {37},
	number = {6},
	pages = {2300--2323},
	month = {June},
	year = {2022},
	doi = {10.1080/10556788.2022.2078824},
	html = {https://www.tandfonline.com/doi/full/10.1080/10556788.2022.2078824},
	pdf = {medphys/adarad.pdf},
	code = {https://github.com/anqif/adarad},
	abstract = {We present an optimization-based approach to radiation treatment planning over time. Our approach formulates treatment planning as an optimal control problem with nonlinear patient health dynamics derived from the standard linear-quadratic cell survival model. As the formulation is nonconvex, we propose a method for obtaining an approximate solution by solving a sequence of convex optimization problems. This method is fast, efficient, and robust to model error, adapting readily to changes in the patient's health between treatment sessions. Moreover, we show that it can be combined with the operator splitting method ADMM to produce an algorithm that is highly scalable and can handle large clinical cases. We introduce an open-source Python implementation of our algorithm, AdaRad, and demonstrate its performance on several examples.}
}

@phdthesis{FuStanfordPhDEE:2021,
	author = {A. Fu and S. Boyd and L. Xing and B. Narasimhan and J. Duchi},
	title = {Convex Optimization Methods for Adaptive Radiation Therapy},
	school = {Stanford University},
	month = {June},
	year = {2021},
	html = {http://purl.stanford.edu/yk503fd5318},
	pdf = {other/stanford_phd_thesis.pdf}
}

@article{FuZhangBoyd:2020,
	author = {A. Fu and J. Zhang and S. Boyd},
	title = {Anderson Accelerated {D}ouglas-{R}achford Splitting},
	journal = {{SIAM} Journal on Scientific Computing},
	abbr = {SISC},
	volume = {42},
	number = {6},
	pages = {A3560--A3583},
	month = {November},
	year = {2020},
	doi = {10.1137/19M1290097},
	html = {https://epubs.siam.org/doi/10.1137/19M1290097},
	pdf = {optim/a2dr.pdf},
	supp = {supp/a2dr_supplement.pdf},
	code = {https://github.com/cvxgrp/a2dr},
	abstract = {We consider the problem of nonsmooth convex optimization with linear equality constraints, where the objective function is only accessible through its proximal operator. This problem arises in many different fields such as statistical learning, computational imaging, telecommunications, and optimal control. To solve it, we propose an Anderson accelerated Douglas--Rachford splitting (A2DR) algorithm, which we show either globally converges or provides a certificate of infeasibility/unboundedness under very mild conditions. Applied to a block separable objective, A2DR partially decouples so that its steps may be carried out in parallel, yielding an algorithm that is fast and scalable to multiple processors. We describe an open-source implementation and demonstrate its performance on a wide range of examples.},
	selected = {true}
}

@article{FuNarasimhanBoyd:2020,
	author = {A. Fu and B. Narasimhan and S. Boyd},
	title = {{CVXR}: An {R} Package for Disciplined Convex Optimization},
	journal = {Journal of Statistical Software},
	abbr = {JSS},
	volume = {94},
	number = {14},
	pages = {1--34},
	month = {September},
	year = {2020},
	doi = {10.18637/jss.v094.i14},
	html = {https://www.jstatsoft.org/article/view/v094i14},
	pdf = {optim/cvxr.pdf},
	code = {https://cvx.rbind.io},
	abstract = {CVXR is an R package that provides an object-oriented modeling language for convex optimization, similar to CVX, CVXPY, YALMIP, and Convex.jl. It allows the user to formulate convex optimization problems in a natural mathematical syntax rather than the restrictive form required by most solvers. The user specifies an objective and set of constraints by combining constants, variables, and parameters using a library of functions with known mathematical properties. CVXR then applies signed disciplined convex programming (DCP) to verify the problem’s convexity. Once verified, the problem is converted into standard conic form using graph implementations and passed to a cone solver such as ECOS or SCS. We demonstrate CVXR’s modeling framework with several applications.},
	selected = {true}
}

@article{FuUngunXing:2019,
	author = {A. Fu and B. Ungun and L. Xing and S. Boyd},
	title = {A Convex Optimization Approach to Radiation Treatment Planning with Dose Constraints},
	journal = {Optimization and Engineering},
	abbre = {OPTE},
	volume = {20},
	number = {1},
	pages = {277--300},
	month = {March},
	year = {2019},
	doi = {10.1007/s11081-018-9409-2},
	html = {https://link.springer.com/article/10.1007/s11081-018-9409-2},
	pdf = {medphys/conrad.pdf},
	code = {https://github.com/bungun/conrad},
	abstract = {We present a method for handling dose constraints as part of a convex programming framework for inverse treatment planning. Our method uniformly handles mean dose, maximum dose, minimum dose, and dose-volume (i.e., percentile) constraints as part of a convex formulation. Since dose-volume constraints are non-convex, we replace them with a convex restriction. This restriction is, by definition, conservative; to mitigate its impact on the clinical objectives, we develop a two-pass planning algorithm that allows each dose-volume constraint to be met exactly on a second pass by the solver if its corresponding restriction is feasible on the first pass. In another variant, we add slack variables to each dose constraint to prevent the problem from becoming infeasible when the user specifies an incompatible set of constraints or when the constraints are made infeasible by our restriction. Finally, we introduce ConRad, a Python-embedded open-source software package for convex radiation treatment planning. ConRad implements the methods described above and allows users to construct and plan cases through a simple interface.}
}

@article{GlembockiRendellAlexon:2009,
	author = {O. J. Glembocki and R. W. Rendell and D. A. Alexon and S. M. Prokes and A. Fu and M. A. Mastro},
	title = {Dielectric-Substrate-Induced Surface-Enhanced {R}aman Scattering},
	journal = {Physical Review B},
	abbr = {PhysRev},
	volume = {80},
	number = {8},
	pages = {085416},
	month = {August},
	year = {2009},
	doi = {10.1103/PhysRevB.80.085416},
	html = {https://journals.aps.org/prb/abstract/10.1103/PhysRevB.80.085416},
	pdf = {other/PhysRevB.80.085416.pdf},
	abstract = {It is shown through experimental mapping of surface-enhanced Raman scattering (SERS) from dielectric core nanowires exposed to benzene thiol that any dielectric substrate plays a critical role in the SERS enhancement. Theoretical calculations of the plasmonic enhancement using finite element methods confirms the role that the substrate plays in increasing the intensity and spatial extent of the SERS enhancement. It is shown that because of the cylindrical shape of the nanowires, significant SERS hot spots form not only between crossed nanowires but also at the point of contact between the nanowires and the substrate on which they are placed. This result also applies to any structure whose geometry results in a point or line contact with an underlying substrate.}
}

@article{ShullProvenzanoShapiro:2006,
	author = {R. D. Shull and V. Provenzano and A. J. Shapiro and A. Fu and M. W. Lufaso and J. Karapetrova and G. Kletetschka and V. Mikula},
	title = {The Effect of Small Metal Additions ({C}o, {C}u, {G}a, {M}n, {A}l, {B}i, {S}n) on the Magnetocaloric Properties of the {G}d5{G}e2{S}i2 Alloy},
	journal = {Journal of Applied Physics},
	abbr = {JAP},
	volume = {99},
	number = {8},
	pages = {08K908},
	month = {April},
	year = {2006},
	doi = {10.1063/1.2173632},
	html = {https://aip.scitation.org/doi/10.1063/1.2173632},
	pdf = {other/JApplPhys.99.08K908.pdf},
	abstract = {The structural and magnetic properties of arc-melted and homogenized (1300 C, 1 h) alloys of Gd5Ge1.9Si2X0.1 (X = Cu, Co, Ga, Mn, Al, Bi, or Sn) were investigated by powder x-ray diffraction, scanning electron microscopy, energy dispersive spectroscopy, and magnetometry. The addition of Cu, Ga, Mn, and Al completely eliminated the large hysteresis losses present in the undoped Gd5Ge2Si2 alloy between 270 and 330 K, broadened the magnetic entropy change $\Delta$ Sm peak, and shifted its peak value from 275 to 305 K similar to that observed earlier for Gd5Ge1.9Si2Fe0.1. The addition of Bi or Sn had a negligible effect on either the alloy hysteresis losses or the characteristics of the $\Delta$ Sm vs T peak. The microstructure of the alloy doped with Cu, Co, Ga, Mn, or Al consisted of a majority phase (depleted of silicon) and a minor intergranular phase (rich in silicon and of the corresponding metal additive). For Bi or Sn doping, the microstructure consisted of only the Gd5Ge2Si2 phase. Low temperature x-ray diffraction data on an Fe-doped sample showed the same spectra at 245 and 300 K, consistent with the majority phase possessing an orthorhombic structure. Refrigeration capacity calculations show that Gd5Ge1.9Si2X0.1 (X = Fe, Cu, Co, Ga, Mn, or Al) alloys are superior magnetic refrigerants compared to the undoped Gd5Ge2Si2 alloy.}
}

@article{HerKoyamaWatanbe:2005,
	author = {J. L. Her and K. Koyama and K. Watanabe and V. Provenzano and A. Fu and A. J. Shapiro and R. D. Shull},
	title = {High-Magnetic Field X-ray Diffraction Studies on {G}d5({G}e(2-x){F}e(x)){S}i2 ($x = 0.05$ and $0.2$)},
	journal = {Materials Transactions},
	abbr = {MaterTrans},
	volume = {46},
	number = {9},
	pages = {2011--2014},
	month = {September},
	year = {2005},
	doi = {10.2320/matertrans.46.2011},
	html = {https://www.jstage.jst.go.jp/article/matertrans/46/9/46_9_2011/_article},
	pdf = {other/MaterTrans.46.2011.pdf},
	abstract = {We performed the powder X-ray diffraction measurements in magnetic fields up to 5 T for Gd5(Ge1.95Fe0.05)Si2 and Gd5(Ge1.8Fe0.2)Si2. With heating from 8 K, the matrix of Gd5(Ge1.95Fe0.05)Si2 clearly shows a structural transition from an orthorhombic to a monoclinic structure at the Curie temperature (TC 1/4 276 K). On the other hand, the matrix of Gd5(Ge1.8Fe0.2)Si2 with the orthorhombic structure in the ferromagnetic state shows two-phases co-existence of the orthorhombic and the monoclinic structures above TC 1/4 303 K, indicating that a small amount of the matrix participates in the transformation. For both samples, the monoclinic structure is suppressed but the orthorhombic structure is enhanced just above TC by applying a magnetic field, which closely relates to the magnetization process.}
}
